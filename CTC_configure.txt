[Layer0]
layer_name = Cnn		
input_dim = -1,40
input_channels = 1                	
filter_nums = 32
filter_size = 3,3               
stride = 2,2 
output_dim = -1,20                  
ln = True			
padding = SAME                 
acn = Relu                      


[Layer1]
layer_name = Cnn
input_dim = -1,20 
input_channels = 32		
filter_nums = 32
filter_size = 3,3
stride = 2,2
output_dim = -1,10
ln = True	
padding = SAME 
acn = Relu


[Layer2]
layer_name = Cnn
input_dim = -1,10
input_channels = 32			
filter_nums = 64
filter_size = 3,3
stride = 1,1
output_dim = -1,10
ln = True
Padding = SAME	
acn = Relu			



[Layer3]
layer_name = GRU
input_dim = 640			
output_dim = 300		
num_units = 300			
forget_bias = 0.95		
ln = True	 
acn = Relu			

[Layer4]
layer_name = GRU
input_dim = 300			
output_dim = 300		
num_units = 300			
forget_bias = 0.95		
ln = True	 
acn = Relu			



[Layer5]
layer_name = GRU
input_dim = 300			
output_dim = 300		
num_units = 300			
forget_bias = 0.95		
ln = True	 
acn = Relu			


[Layer6]
layer_name = GRU
input_dim = 300			
output_dim = 300		
num_units = 300			
forget_bias = 0.95		
ln = True	 
acn = Relu			

[Layer7]
layer_name = GRU
input_dim = 300			
output_dim = 300		
num_units = 300			
forget_bias = 0.95		
ln = True	 
acn = Relu			



[Layer8]
layer_name = LinearTransform
input_dim = 300			
output_dim = 2			
svd = False
ln = False	 
acn = Softmax			



[Graph]
Layer_nums = 9 			
log_dir = /home/yyliu/tf/
trn_dir = /data5/yyliu/tf/train
cv_dir = /data5/yyliu/tf/test
mod_dir = /home/yyliu/tf/model
iter = 100
gpu_nums = 10
batch_size = 128
Capacity = 5000
drop_rate = 0.9			
learn_rate = 0.5		
loss = crossentropy		
optimizer = GradientDescent	



